{"componentChunkName":"component---src-pages-solution-cp-4-d-async-mdx","path":"/solution/cp4d/async/","result":{"pageContext":{"frontmatter":{"title":"IBM Cloud Pak for Data - Anomaly Detection from Streaming Events","description":"IBM Cloud Pak for Data - Anomaly Detection from Streaming Events"},"relativePagePath":"/solution/cp4d/async.mdx","titleType":"append","MdxNode":{"id":"9621cb23-1d8c-5ab8-b881-694caae16575","children":[],"parent":"d95c964b-7926-5d15-94a7-a7d1f7d6ea65","internal":{"content":"---\ntitle: IBM Cloud Pak for Data - Anomaly Detection from Streaming Events\ndescription: IBM Cloud Pak for Data - Anomaly Detection from Streaming Events\n---\n\n ![1](./images/asyn-architect.png)\n \n \nThis section will show how to use Cloud Pak for Data for anomaly detection from streaming events using the anomaly detection model deployed in Watson Machine Learning.  The events will come to an event bus, Kafka, and from there the anomaly detection model will be called in an asychronous manner.  In this usage pattern, the events are assumed to be coming into the event bus, Kafka, in Cloud Pak for Integration.  There would be a consumer running in Cloud Pak for Data that will consume the events at a scheduled frequency.  The consumer will call the deployed anomaly detection model for each event to identify those that are anomalous.  \n\nBelow is the notebook that achieves the above goal. \n\nThe notebook internally calls this model deployment endpoint of the anomaly detection model:\n\n ![2](./images/asyn-dep.png)\n\nThe notebook can be run as a job using the job framework in Cloud Pak for Data\n\n ![3](./images/asyn-jobdetails.png)\n\nAfter creating the job, the status of the streaming job can be monitored using the Cloud Pak for Data interface. \n\n ![4](./images/asyn-jobruns.png)\n\nSince this model is monitored in Watson OpenScale, the predictions can be tracked over a period of time.\n\n ![5](./images/asyn-os.png)\n \n \n\n","type":"Mdx","contentDigest":"f8dc96aba7554c79c469f992d16c481c","counter":293,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"IBM Cloud Pak for Data - Anomaly Detection from Streaming Events","description":"IBM Cloud Pak for Data - Anomaly Detection from Streaming Events"},"exports":{},"rawBody":"---\ntitle: IBM Cloud Pak for Data - Anomaly Detection from Streaming Events\ndescription: IBM Cloud Pak for Data - Anomaly Detection from Streaming Events\n---\n\n ![1](./images/asyn-architect.png)\n \n \nThis section will show how to use Cloud Pak for Data for anomaly detection from streaming events using the anomaly detection model deployed in Watson Machine Learning.  The events will come to an event bus, Kafka, and from there the anomaly detection model will be called in an asychronous manner.  In this usage pattern, the events are assumed to be coming into the event bus, Kafka, in Cloud Pak for Integration.  There would be a consumer running in Cloud Pak for Data that will consume the events at a scheduled frequency.  The consumer will call the deployed anomaly detection model for each event to identify those that are anomalous.  \n\nBelow is the notebook that achieves the above goal. \n\nThe notebook internally calls this model deployment endpoint of the anomaly detection model:\n\n ![2](./images/asyn-dep.png)\n\nThe notebook can be run as a job using the job framework in Cloud Pak for Data\n\n ![3](./images/asyn-jobdetails.png)\n\nAfter creating the job, the status of the streaming job can be monitored using the Cloud Pak for Data interface. \n\n ![4](./images/asyn-jobruns.png)\n\nSince this model is monitored in Watson OpenScale, the predictions can be tracked over a period of time.\n\n ![5](./images/asyn-os.png)\n \n \n\n","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/solution/cp4d/async.mdx"}}}}