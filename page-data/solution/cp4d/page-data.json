{"componentChunkName":"component---src-pages-solution-cp-4-d-index-mdx","path":"/solution/cp4d/","result":{"pageContext":{"frontmatter":{"title":"IBM Cloud Pak for Data - data collection","description":"IBM Cloud Pak for Data - data collection"},"relativePagePath":"/solution/cp4d/index.mdx","titleType":"append","MdxNode":{"id":"08834507-da83-5d7a-b3b5-d2dd5c39dc56","children":[],"parent":"7e4f86c8-002d-52d4-8250-9d55bc71458d","internal":{"content":"---\ntitle: IBM Cloud Pak for Data - data collection\ndescription: IBM Cloud Pak for Data - data collection\n---\n\nNow we shall show how various components of Cloud Pak For Data can be used to Develop, Deploy and Monitor an Anomaly detection Model in a very quick turn around time. \n\n ![1](./images/cp4d-home.png)\n\nLike any other Cloud Pak, Cloud Pak for Data can also run in any Cloud infrastructure - IBM Cloud, Azure, Google or Amazon or even in On Premise infrastructure.\n\nThe refrigerated containers, those would be used to ship the Vaccines to the Medical facilities, need monitoring. That is to ensure that all sensors within the containers are working properly so that its internal control system maintains  the necessary temperature and the concentration of cryogenic fluids. Otherwise the Vaccines would be spoiled and cannot be used for the treatment of patients.\n\nThe data of various sensors from the containers (while they are on job to fulfill a shipment) can be continuously captured as event data and kept in any kind of datastore. The same can be then used to build a AI model to continuously check if any irregularity happening in the Containers while in move (which can in turn spoil the Vaccines).\n\nCloud Pak for Data can access data available in variety of Data Stores - Relational, No SQL, Message Queues, HDFS; around 40 different types of them. The Datastores can be public cloud, private cloud or on premise.\n  \n  ![2](./images/db-connection.png)\n\nHere we are assuming the Data is available in a DB2 relational store and accessing the same in Data Refinery Component on Cloud Pak For Data.\n\n  ![3](./images/data-refinery.png)\n  \nThe Model Developer, the Data Scientist, can access the Data in Data Refinery and at first Profile the Data. \n\nAfter that she needs to decide how to define Anomaly. In this type of cases, a typical way to define anomaly is based on difference in Target Temperature and Actual Temperature. If that difference is high then it signifies that the Control system is not working as needed. \n\nSo she may create a dataset to build an Anomaly detection model based on concentration of various fluids as independent variables and an AnomalyFlg as Dependent variable. The Anomaly flag would be derived based on the certain threshold of the temperature difference mentioned before. She may also add some other factual indicators like number of minutes doors were open, number of defrost cycles, power, etc as the additional features.\n\nShe can create this dataset for development of the model based on the original sensor datasets through few quick steps using Data Refinery.\n\n[Showing Following Steps using Refinery - Create TempDiff value, Anomaly Flg, Remove other fields]\n\nNow she can use Auto AI of Cloud Pak For Data to build the Model by running multiple data science experiments within few minutes.\n\n ![4](../../analyze/images/autoai-2.png)\n\n\n[Showing Following Steps using AutoAI - Ingest Prepared Data, Setup Experiments, Choose Right Model, Save the Model]\n\n\nNow she can immediately deploy the Model so that Model can be called for Anomaly prediction from anywhere, any application over Rest Interface. \n\n5. [Cloud Pak For Data - WML Screen]\n\nThis Model can predict whether there is any possible Anomalous behaviour in Container because of faulty Temperature sensor. Appropriate action can be taken based on that prediction.\n\n\n6. [Cloud Pak For Data - Open Scale Home Screen]\n\nThe deployed Model can then further be monitored using Open Scale of Cloud Pak For Data. It can be used for Explainaing why Model is predicting in a particular way, Is there any drift in Input Data, is there any possible Bias in the Model that comes up after few predictions, etc.\n\nFor example  Whether a prediction is based on the time the doors were open, concentration of CO2, or based on Defrost cycle. Also is there any Drift in Input Data (the concentration of fluids, time doors are open, defrost cycle, etc) over a period of time w.r.t the training data (historical value). All these inputs can further help in taking any decision on what to do in such situations.\n \nCloud Pak for data makes the data ready in days and ensures that the data scientists can use their tooling of preference whose security is ensured by IBM using Watson Studio.  Business can have the confidence to know what were the factors and data used by the model to make a decision.\n\nAnother popular date sources or data connection is streaming data from other streaming data platform, like IBM Event Stream in Cloud Pak For Integration.\n\n![3](./images/eventStream.jpg)\n","type":"Mdx","contentDigest":"7b11520b6615fa1071baa2d9c60d932c","counter":259,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"IBM Cloud Pak for Data - data collection","description":"IBM Cloud Pak for Data - data collection"},"exports":{},"rawBody":"---\ntitle: IBM Cloud Pak for Data - data collection\ndescription: IBM Cloud Pak for Data - data collection\n---\n\nNow we shall show how various components of Cloud Pak For Data can be used to Develop, Deploy and Monitor an Anomaly detection Model in a very quick turn around time. \n\n ![1](./images/cp4d-home.png)\n\nLike any other Cloud Pak, Cloud Pak for Data can also run in any Cloud infrastructure - IBM Cloud, Azure, Google or Amazon or even in On Premise infrastructure.\n\nThe refrigerated containers, those would be used to ship the Vaccines to the Medical facilities, need monitoring. That is to ensure that all sensors within the containers are working properly so that its internal control system maintains  the necessary temperature and the concentration of cryogenic fluids. Otherwise the Vaccines would be spoiled and cannot be used for the treatment of patients.\n\nThe data of various sensors from the containers (while they are on job to fulfill a shipment) can be continuously captured as event data and kept in any kind of datastore. The same can be then used to build a AI model to continuously check if any irregularity happening in the Containers while in move (which can in turn spoil the Vaccines).\n\nCloud Pak for Data can access data available in variety of Data Stores - Relational, No SQL, Message Queues, HDFS; around 40 different types of them. The Datastores can be public cloud, private cloud or on premise.\n  \n  ![2](./images/db-connection.png)\n\nHere we are assuming the Data is available in a DB2 relational store and accessing the same in Data Refinery Component on Cloud Pak For Data.\n\n  ![3](./images/data-refinery.png)\n  \nThe Model Developer, the Data Scientist, can access the Data in Data Refinery and at first Profile the Data. \n\nAfter that she needs to decide how to define Anomaly. In this type of cases, a typical way to define anomaly is based on difference in Target Temperature and Actual Temperature. If that difference is high then it signifies that the Control system is not working as needed. \n\nSo she may create a dataset to build an Anomaly detection model based on concentration of various fluids as independent variables and an AnomalyFlg as Dependent variable. The Anomaly flag would be derived based on the certain threshold of the temperature difference mentioned before. She may also add some other factual indicators like number of minutes doors were open, number of defrost cycles, power, etc as the additional features.\n\nShe can create this dataset for development of the model based on the original sensor datasets through few quick steps using Data Refinery.\n\n[Showing Following Steps using Refinery - Create TempDiff value, Anomaly Flg, Remove other fields]\n\nNow she can use Auto AI of Cloud Pak For Data to build the Model by running multiple data science experiments within few minutes.\n\n ![4](../../analyze/images/autoai-2.png)\n\n\n[Showing Following Steps using AutoAI - Ingest Prepared Data, Setup Experiments, Choose Right Model, Save the Model]\n\n\nNow she can immediately deploy the Model so that Model can be called for Anomaly prediction from anywhere, any application over Rest Interface. \n\n5. [Cloud Pak For Data - WML Screen]\n\nThis Model can predict whether there is any possible Anomalous behaviour in Container because of faulty Temperature sensor. Appropriate action can be taken based on that prediction.\n\n\n6. [Cloud Pak For Data - Open Scale Home Screen]\n\nThe deployed Model can then further be monitored using Open Scale of Cloud Pak For Data. It can be used for Explainaing why Model is predicting in a particular way, Is there any drift in Input Data, is there any possible Bias in the Model that comes up after few predictions, etc.\n\nFor example  Whether a prediction is based on the time the doors were open, concentration of CO2, or based on Defrost cycle. Also is there any Drift in Input Data (the concentration of fluids, time doors are open, defrost cycle, etc) over a period of time w.r.t the training data (historical value). All these inputs can further help in taking any decision on what to do in such situations.\n \nCloud Pak for data makes the data ready in days and ensures that the data scientists can use their tooling of preference whose security is ensured by IBM using Watson Studio.  Business can have the confidence to know what were the factors and data used by the model to make a decision.\n\nAnother popular date sources or data connection is streaming data from other streaming data platform, like IBM Event Stream in Cloud Pak For Integration.\n\n![3](./images/eventStream.jpg)\n","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/solution/cp4d/index.mdx"}}}}