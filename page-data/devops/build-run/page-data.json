{"componentChunkName":"component---src-pages-devops-build-run-mdx","path":"/devops/build-run/","result":{"pageContext":{"frontmatter":{"title":"Build and Run"},"relativePagePath":"/devops/build-run.mdx","titleType":"append","MdxNode":{"id":"4557c4b2-5144-5f1b-a80b-0e3c757fe53e","children":[],"parent":"eea2315e-e1bc-5029-8d2d-f53edf657da2","internal":{"content":"---\ntitle: Build and Run\n---\n\n### An alternate approach is to setup a CI/CD pipeline\n\nWe have adopted the Git Action to manage the [continuous integration](https://github.com/ibm-cloud-architecture/refarch-kc-gitops/blob/master/KContainer-CI-Strategy.md), and ArgoCD for the continuous deployment. The build process will build the following images:\n\n* [https://hub.docker.com/repository/docker/ibmcase/kcontainer-reefer-simulator]\n\nHelm charts are added for the simulator and the scoring agent, using `helm create` command, and then the values.yaml and deployment.yaml files were updated to set environment variables and other parameters.\n\n## Test sending a simulation control to the POST api\n\nThe script `sendSimulControl.sh` is used for that. The usage looks like:  `sendSimulControl.sh hostname simultype (co2sensor | o2sensor | poweroff) containerID nb_of_records`\n\n```\npwd\nrefarch-reefer-ml\n./scripts/sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor C01 2000\n```\n\nIf you use no argument for this script, it will send co2sensor control to the service running on our openshift cluster on IBM Cloud.\n\nLooking at the logs from the pod using `oc logs reefersimulator-3-jdh2v` you can see something like:\n\n```\n     \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\"\n    {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4}\n    Generating  10  Co2 metrics\n```\n\nWe will see how those events are processed in the next section.\n\n\n\n## The predictive scoring agent\n\nApplying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that calls the serialized analytical model. The code in the `scoring\\eventConsumer` folder.\n\nApplying a TDD approach we start by a TestScoring.py class.\n\n```python\nimport unittest\nfrom domain.predictservice import PredictService\n\nclass TestScoreMetric(unittest.TestCase):\n    def testCreation(self):\n        serv = PredictService\n        \nif __name__ == '__main__':\n    unittest.main()\n```\n\nUse the same python environment with docker:\n\n```\n./startPythonEnv\nroot@1de81b16f940:/# export PYTHONPATH=/home/scoring/eventConsumer\nroot@1de81b16f940:/# cd /home/scoring/eventConsumer\nroot@1de81b16f940:/home/scoring/eventConsumer# python tests/TestScoring.py \n```\n\nTest fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder).\n\n```python\nimport pickle\n\nclass PredictService:\n    def __init__(self,filename = \"domain/model_logistic_regression.pkl\"):\n        self.model = pickle.load(open(filename,\"rb\"),encoding='latin1')\n    \n    \n    def predict(self,metricEvent):\n        TESTDATA = StringIO(metricEvent)\n        data = pd.read_csv(TESTDATA, sep=\",\")\n        data.columns = data.columns.to_series().apply(lambda x: x.strip())\n        X = data[ X = data[FEATURES_NAMES]]\n        return self.model.predict(X)\n    \n```\n\nNext we need to test a predict on an event formated as a csv string. The test looks like:\n\n```\n    serv = PredictService()\n    header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\"\n    event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\"\n    record=header+\"\\n\"+event\n    print(serv.predict(record))\n```\n\nSo the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. \n\nThe Scoring Agent code of this app is [ScoringAgent.py](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/scoring/ScoringAgent.py) module. It starts a consumer to get messages from Kafka. And when a message is received, it needs to do some data extraction and transformation and then use the predictive service.\n\nDuring the tests we have issue in the data quality, so it is always a good practice to add a validation function to assess if all the records are good. For production, this code needs to be enhanced for better error handling an reporting.\n\n### Run locally\n\nUnder `scoring\\eventConsumer` folder, set the environment variables for KAFKA using the commands below: (It uses event streams on IBM Cloud)\n\n```\nexport KAFKA_BROKERS=broker-3.eventstreams.cloud.ibm.com:9093,broker-1.eventstreams.cloud.ibm.com:9093,broker-0.eventstreams.cloud.ibm.com:9093,broker-5.eventstreams.cloud.ibm.com:9093,broker-2.eventstreams.cloud.ibm.com:9093,broker-4.eventstreams.cloud.ibm.com:9093\nexport KAFKA_APIKEY=\"set-api-key-for-eventstreams-on-cloud\"\n\ndocker run -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY  -v $(pwd)/..:/home -ti ibmcase/python bash -c \"cd /home/scoring && export PYTHONPATH=/home && python ScoringAgent.py\"\n```\n\n### Scoring: Build and run on Openshift\n\nThe first time we need to add the application to the existing project, run the following command:\n\n```\noc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=scoring/eventConsumer --name reeferpredictivescoring\n```\n\nThis command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. It use the `--context` flag to define what to build and run. With this capability we can use the same github repository for different sub component.\n\nAs done for simulator, the scoring service needs environment variables. We can set them using the commands\n\n```\noc set env dc/reeferpredictivescoring KAFKA_BROKERS=$KAFKA_BROKERS\noc set env dc/reeferpredictivescoring KAFKA_APIKEY=$KAFKA_APIKEY\noc set env dc/reeferpredictivescoring KAFKA_CERT=/opt/app-root/src/es-cert.pem\n```\n\nbut we have added a script for you to do so. This script needs only to be run at the first deployment. It leverage the common setenv scripts:\n\n```\n../scripts/defEnvVarInOpenShift.sh \n```\n\nThe list of running pods should show the build pods for this application:\n\n```\n oc get pods\n reeferpredictivescoring-1-build   1/1       Running      0          24s\n```\n\nTo run the build again after commit code to github:\n\n```\noc start-build reeferpredictivescoring \n\n# or from local file system\noc start-build reeferpredictivescoring --from-file=.\n```\n\nTo see the log:\n\n```\n oc logs reeferpredictivescoring-2-rxr6j\n```\n\nTo be able to run on Openshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the `environment` file under the `.s2i ` folder.\n\nThe scoring service has no API exposed to the external world, so we do not need to create a `Route` or ingress.\n\nSee the [integration test](#integration-tests) section to see a demonstration of the solution end to end.\n\n\n### Build docker images\n\n\n\nFor the scoring agent:\n\n```\n# scoring folder\n\n```\n\n#### Run kafka on your laptop\n\nFor development purpose, you can also run kafka, zookeeper and postgresql and the solution on your laptop. For that read [this readme](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/docker/README.md) for details.","type":"Mdx","contentDigest":"c0c26747544e78257d8365f7146cba40","counter":234,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Build and Run"},"exports":{},"rawBody":"---\ntitle: Build and Run\n---\n\n### An alternate approach is to setup a CI/CD pipeline\n\nWe have adopted the Git Action to manage the [continuous integration](https://github.com/ibm-cloud-architecture/refarch-kc-gitops/blob/master/KContainer-CI-Strategy.md), and ArgoCD for the continuous deployment. The build process will build the following images:\n\n* [https://hub.docker.com/repository/docker/ibmcase/kcontainer-reefer-simulator]\n\nHelm charts are added for the simulator and the scoring agent, using `helm create` command, and then the values.yaml and deployment.yaml files were updated to set environment variables and other parameters.\n\n## Test sending a simulation control to the POST api\n\nThe script `sendSimulControl.sh` is used for that. The usage looks like:  `sendSimulControl.sh hostname simultype (co2sensor | o2sensor | poweroff) containerID nb_of_records`\n\n```\npwd\nrefarch-reefer-ml\n./scripts/sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor C01 2000\n```\n\nIf you use no argument for this script, it will send co2sensor control to the service running on our openshift cluster on IBM Cloud.\n\nLooking at the logs from the pod using `oc logs reefersimulator-3-jdh2v` you can see something like:\n\n```\n     \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\"\n    {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4}\n    Generating  10  Co2 metrics\n```\n\nWe will see how those events are processed in the next section.\n\n\n\n## The predictive scoring agent\n\nApplying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that calls the serialized analytical model. The code in the `scoring\\eventConsumer` folder.\n\nApplying a TDD approach we start by a TestScoring.py class.\n\n```python\nimport unittest\nfrom domain.predictservice import PredictService\n\nclass TestScoreMetric(unittest.TestCase):\n    def testCreation(self):\n        serv = PredictService\n        \nif __name__ == '__main__':\n    unittest.main()\n```\n\nUse the same python environment with docker:\n\n```\n./startPythonEnv\nroot@1de81b16f940:/# export PYTHONPATH=/home/scoring/eventConsumer\nroot@1de81b16f940:/# cd /home/scoring/eventConsumer\nroot@1de81b16f940:/home/scoring/eventConsumer# python tests/TestScoring.py \n```\n\nTest fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder).\n\n```python\nimport pickle\n\nclass PredictService:\n    def __init__(self,filename = \"domain/model_logistic_regression.pkl\"):\n        self.model = pickle.load(open(filename,\"rb\"),encoding='latin1')\n    \n    \n    def predict(self,metricEvent):\n        TESTDATA = StringIO(metricEvent)\n        data = pd.read_csv(TESTDATA, sep=\",\")\n        data.columns = data.columns.to_series().apply(lambda x: x.strip())\n        X = data[ X = data[FEATURES_NAMES]]\n        return self.model.predict(X)\n    \n```\n\nNext we need to test a predict on an event formated as a csv string. The test looks like:\n\n```\n    serv = PredictService()\n    header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\"\n    event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\"\n    record=header+\"\\n\"+event\n    print(serv.predict(record))\n```\n\nSo the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. \n\nThe Scoring Agent code of this app is [ScoringAgent.py](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/scoring/ScoringAgent.py) module. It starts a consumer to get messages from Kafka. And when a message is received, it needs to do some data extraction and transformation and then use the predictive service.\n\nDuring the tests we have issue in the data quality, so it is always a good practice to add a validation function to assess if all the records are good. For production, this code needs to be enhanced for better error handling an reporting.\n\n### Run locally\n\nUnder `scoring\\eventConsumer` folder, set the environment variables for KAFKA using the commands below: (It uses event streams on IBM Cloud)\n\n```\nexport KAFKA_BROKERS=broker-3.eventstreams.cloud.ibm.com:9093,broker-1.eventstreams.cloud.ibm.com:9093,broker-0.eventstreams.cloud.ibm.com:9093,broker-5.eventstreams.cloud.ibm.com:9093,broker-2.eventstreams.cloud.ibm.com:9093,broker-4.eventstreams.cloud.ibm.com:9093\nexport KAFKA_APIKEY=\"set-api-key-for-eventstreams-on-cloud\"\n\ndocker run -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY  -v $(pwd)/..:/home -ti ibmcase/python bash -c \"cd /home/scoring && export PYTHONPATH=/home && python ScoringAgent.py\"\n```\n\n### Scoring: Build and run on Openshift\n\nThe first time we need to add the application to the existing project, run the following command:\n\n```\noc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=scoring/eventConsumer --name reeferpredictivescoring\n```\n\nThis command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. It use the `--context` flag to define what to build and run. With this capability we can use the same github repository for different sub component.\n\nAs done for simulator, the scoring service needs environment variables. We can set them using the commands\n\n```\noc set env dc/reeferpredictivescoring KAFKA_BROKERS=$KAFKA_BROKERS\noc set env dc/reeferpredictivescoring KAFKA_APIKEY=$KAFKA_APIKEY\noc set env dc/reeferpredictivescoring KAFKA_CERT=/opt/app-root/src/es-cert.pem\n```\n\nbut we have added a script for you to do so. This script needs only to be run at the first deployment. It leverage the common setenv scripts:\n\n```\n../scripts/defEnvVarInOpenShift.sh \n```\n\nThe list of running pods should show the build pods for this application:\n\n```\n oc get pods\n reeferpredictivescoring-1-build   1/1       Running      0          24s\n```\n\nTo run the build again after commit code to github:\n\n```\noc start-build reeferpredictivescoring \n\n# or from local file system\noc start-build reeferpredictivescoring --from-file=.\n```\n\nTo see the log:\n\n```\n oc logs reeferpredictivescoring-2-rxr6j\n```\n\nTo be able to run on Openshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the `environment` file under the `.s2i ` folder.\n\nThe scoring service has no API exposed to the external world, so we do not need to create a `Route` or ingress.\n\nSee the [integration test](#integration-tests) section to see a demonstration of the solution end to end.\n\n\n### Build docker images\n\n\n\nFor the scoring agent:\n\n```\n# scoring folder\n\n```\n\n#### Run kafka on your laptop\n\nFor development purpose, you can also run kafka, zookeeper and postgresql and the solution on your laptop. For that read [this readme](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/docker/README.md) for details.","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/devops/build-run.mdx"}}}}